semPaths(path, what = "est", intercepts = F, layout = "circle")
semPaths(model1fit.ungrouped, what = "est", intercepts = F, layout = "circle")
path <- "~/Downloads/timss_mplus_efa_mod(1).out"
semPaths(path, what = "est", intercepts = F, layout = "circle")
measurementInvariance(model = model1, data = data2, std.lv = TRUE, estimator = "WLSMV", strict = TRUE, group = "girl", method = "satorra.bentler.2001")
?"mplus2lavaan"
inp.path <- "~/Downloads/timss_Mplus_EFA_mod.inp"
mplus2lavaan(inp.path)
mplus2lavaan(inp.path)
mplus2lavaan(inp.path)
semPaths(model1fit.ungrouped, what = "est", intercepts = F, layout = "circle")
path <- "~/Downloads/timss_mplus_efa_mod(1).out"
semPaths(path, what = "est", intercepts = F, layout = "circle")
summary(model1fit.ungrouped, fit.measures = TRUE)
parameters <- parameterEstimates(model1fit.ungrouped)
fit <- fitMeasures(model1fit.ungrouped)
#loadings <- get.loadings(data2[1:length(item.list)], model1fit.ungrouped)
#rownames(loadings) <- item.list
#oblimin(loadings) # We could use this to rotate the factors if we had 2 or more factors
observed.variances <- sapply(item.list, function(x) var(data2[,x]))
loadings <- c(.609, .446, .683, .622, .538, .718, .740, .714,
.670, .483, .592, .460,.425, .282, .447, .619, .539, .557,
.857, .855, .695, .696, .320, .572, .550)
names(loadings) <- item.list
residual.variances <- c(.629, .801, .533, .614, .711, .484, .453,
.491, .552, .767, .649, .789, .819, .921,
.800, .616, .709, .689, .265, .270, .517, .516,
.897, .673, .698)
names(residual.variances) <- item.list
reliability <- loadings^2
hist(reliability, main="Reliability of items on math factor", xlab = expression(~ R^{2}))
hist(reliability, main="Reliability of items on math factor", xlab = expression(~ R^{2}),
color = "blue")
hist(reliability, main="Reliability of items on math factor", xlab = expression(~ R^{2}),
col = "blue")
summary(reliability)
sort(reliability)
reliability(model1fit.ungrouped)
summary(model1fit.ungrouped, fit.measures = TRUE)
model1fit.ungrouped
model1
summary(model1fit.ungrouped, fit.measures = TRUE)
read.table("~/Downloads/MathScores.dat")
est.scores <- read.table("~/Downloads/MathScores.dat")
View(est.scores)
colnames(est.scores) <- c(item.list, "MATH", "GIRL")
est.scores$gender <- ifelse(est.scores$GIRL==1, "female", "male")
histogram(~ MATH | gender, data=est.scores)
require(lattice)
histogram(~ MATH | gender, data=est.scores)
histogram(~ MATH , data=est.scores)
qqnorm(est.scores$MATH)
qqline(est.scores$MATH)
?qqnorm
qqnorm(est.scores$MATH, main="Normal Q-Q Plot of estimated math scores",
xlab="Normal Distribution", ylab="Estimated Factor Scores")
qqline(est.scores$MATH)
mean(est.scores$MATH)
var(est.scores$MATH)
?qqnorm
qqnorm(est.scores$MATH, main="Normal Q-Q Plot of estimated math scores",
xlab="Normal Distribution", ylab="Estimated Factor Scores",
xlim=c(-3.5,3.5),ylim=c(-3.5,3.5))
qqline(est.scores$MATH)
qqnorm(est.scores$MATH, main="Normal Q-Q Plot of estimated math scores",
xlab="Normal Distribution", ylab="Estimated Factor Scores")
qqline(est.scores$MATH)
mean(est.scores[which(est.scores$GIRL == 1)]$MATH)
mean(est.scores[which(est.scores$GIRL == 1), "MATH"])
mean(est.scores[which(est.scores$GIRL == 0), "MATH"])
var(est.scores[which(est.scores$GIRL == 0), "MATH"])
var(est.scores[which(est.scores$GIRL == 1), "MATH"])
mean(est.scores[,"MATH"])
sum(est.scores$GIRL)
?t.test
t.test(MATH ~ GIRL, data = est.scores)
thresholds <- c(-.352,.201,.368,1.360,-.571,-.098,-.246,-.905,-.950,.588,-.571,-.905,-.033,-.650,.529, .291,.142,-.299,.194,-0.055,.742,.863,.487,.605,.194)
mean(thresholds)
est.scores$sum.score <- est.scores[,item.list]
est.scores
View(est.scores)
est.scores$sum.score <- sum(est.scores[,item.list])
est.scores <- read.table("~/Downloads/MathScores.dat")
est.scores$gender <- ifelse(est.scores$GIRL==1, "female", "male")
est.scores$sum.score <- sum(est.scores[,item.list])
est.scores
View(est.scores)
colnames(est.scores) <- c(item.list, "MATH", "GIRL")
est.scores$gender <- ifelse(est.scores$GIRL==1, "female", "male")
est.scores <- read.table("~/Downloads/MathScores.dat")
colnames(est.scores) <- c(item.list, "MATH", "GIRL")
est.scores$gender <- ifelse(est.scores$GIRL==1, "female", "male")
est.scores$sum.score <- sum(est.scores[,item.list])
View(est.scores)
t.test(MATH ~ gender, data = est.scores)
?pspearman
?cor
cor(x = est.scores$MATH, y = est.scores$sum.score, method = "spearman")
?rowSums
est.scores$sum.score <- rowSums(est.scores[,item.list])
View(est.scores)
cor(x = est.scores$MATH, y = est.scores$sum.score,
method = "spearman")
?qplot
qplot(x = sum.score, y = MATH, data = est.score, xlab = "Coarse sum scores", ylab = "Estimated factor scores", main = "Scoring Methods Compared")
require(ggplot2)
qplot(x = sum.score, y = MATH, data = est.score, xlab = "Coarse sum scores", ylab = "Estimated factor scores", main = "Scoring Methods Compared")
qplot(x = sum.score, y = MATH, data = est.scores, xlab = "Coarse sum scores", ylab = "Estimated factor scores", main = "Scoring Methods Compared")
?unique
length(unique(est.scores$sum.score))
length(unique(est.scores$MATH))
t.test(sum.scores ~ gender, data = est.scores)
t.test(sum.score ~ gender, data = est.scores)
var(est.scores$sum.score)
sd(est.scores$sum.score)
sd(est.scores$MATH)
t.test(Math ~ gender, data = est.scores)
t.test(MATH ~ gender, data = est.scores)
-0.101041916+0.004516854
0.09652506/0.8874807
11.88623-12.47191
0.58568/5.413365
require(psych)
fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet")
require(psych)
fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores="tenBerge")
psych.factor.analysis <-  fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores="tenBerge")
psych.factor.analysis <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores="tenBerge")
psych.factor.analysis <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet")
psych.factor.analysis <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores = "tenBerge")
psych.factor.analysis.anderson <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores = "Anderson")
psych.factor.analysis.anderson <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores = "Thurstone")
psych.factor.analysis.anderson <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores = "Bartlett")
psych.factor.analysis.bartlett <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores = "Bartlett")
psych.factor.analysis.thurstone <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet", scores = "Thurstone")
psych.factor.analysis.regression <- fa(data[,item.list], nfactors=1, rotate="oblimin", fm="wls", cor="tet")
psych.factor.analysis.bartlett$scores
cor(x = psych.factor.analysis.bartlett$scores, y = est.scores$sum.score,
method = "spearman")
cor(x = psych.factor.analysis.bartlett$scores, y = est.scores$MATH,
method = "spearman")
cor(x = psych.factor.analysis.regression$scores, y = est.scores$MATH,
method = "spearman")
bi.fit
summary(bi.fit, fit.measures = T)
summary(model1fit.ungrouped, fit.measures = T)
t.test(MATH ~ GIRL, data = est.scores)
t.test(sum.score ~ GIRL, data = est.scores)
library(foreign)
?read.spss
data.anorectic <- read.spss('Documents/anorectic.sav', to.data.frame = T)
View(data.anorectic)
summary(anorectic)
summary(data.anorectic)
?fa
library(psych)
symptoms <- colnames(data.anorectic)[1:16]
symptoms
?fa
fa(data.anorectic, nfactors = 1, rotate = 'oblimin', fm = 'pa', use = 'listwise', cor = 'poly')
fa(data.anorectic, nfactors = 1, rotate = 'oblimin', fm = 'pa', cor = 'poly')
fa(data.anorectic[,symptoms], nfactors = 1, rotate = 'oblimin', fm = 'pa', use = 'listwise', cor = 'poly')
fa(data.anorectic[,symptoms], nfactors = c(1,2,3), rotate = 'oblimin', fm = 'pa', use = 'listwise', cor = 'poly')
warnings()
fa(data.anorectic[,symptoms], nfactors = 1, rotate = 'oblimin', fm = 'pa', use = 'listwise', cor = 'poly')
fa(data.anorectic[,symptoms], nfactors = 2, rotate = 'oblimin', fm = 'pa', use = 'listwise', cor = 'poly')
fa(data.anorectic[,symptoms], nfactors = 2, rotate = 'oblimin', fm = 'wls', use = 'listwise', cor = 'poly')
fa(data.anorectic[,symptoms], nfactors = 1, rotate = 'oblimin', fm = 'wls', use = 'listwise', cor = 'poly')
?factanal
?chisq.test
258.473-181.937
104-89
181.937-114.359
89-75
114.359-81.753
75-62
4^3
64^2
4^6
2^3
8^4
2^12
5^7
78125^2
5^14
0:1000
s <- 0:1000
alpha <- .025
eta_decay <- 0.1
min_eta <- 1e-3
eta <- (alpha / (1 + s * eta_decay))
plot(eta)
eta
eta <- max((alpha / (1 + s * eta_decay)), min_eta)
eta
?rep
eta <- max((alpha / (1 + s * eta_decay)), rep(min_eta, length(s))
)
eta <- max((alpha / (1 + s * eta_decay)), rep(min_eta, length(s)))
eta
rep(min_eta, length(s))
?max
eta <- pmax((alpha / (1 + s * eta_decay)), rep(min_eta, length(s)))
eta
dimensions <- c(100,200,250,300,350,400)
performance <- c(.600,.618,.624,.626,.630,.640)
qplot(dimensions,performance)
library(ggplot2)
qplot(dimensions,performance)
qplot(dimensions,performance) + geom_smooth()
qplot(dimensions,performance, ylim = c(.50,.75)) + geom_smooth()
qplot(dimensions,performance, ylim = c(.50,.70)) + geom_smooth()
qplot(dimensions,performance, ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth()
cbind(dimensions, performance, window = c(10,10,10,10,10,10))
data <- cbind(dimensions, performance, window = c(10,10,10,10,10,10))
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth()
data <- data.frame(data)
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth()
?data.frame
a <- c(dimensions=100, performance = .566, window=5)
b <- c(dimensions=200, performance = .585, window=5)
rbind(data, a, b)
b <- c(dimensions=300, performance = .612, window=5)
rbind(data, c)
rbind(data, b)
c <- c(dimensions=300, performance = .612, window=5)
b <- c(dimensions=300, performance = .612, window=5)
data <- rbind(data, a, b, c)
data
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth()
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth(data[data$window == 10])
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth(data[,data$window == 10])
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth(data[data$window == 10,])
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth(data = data, color = factor(window) )
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth(data = data)
qplot(x = dimensions, y = performance, data = data, color = factor(window), ylim = c(.50,.70), main="Model with Negative Sampling") + geom_smooth(aes(group=factor(window)))
qplot(x = dimensions, y = performance, data = data, color = factor(window), main="Model with Negative Sampling") + geom_smooth(aes(group=factor(window)))
6*.2
.25+6*.2
pi/2 * 3
120  <- c(2,2,2,3,5)
p120  <- c(2,2,2,3,5)
2*2*2*3*5
p8 <- c(2,2,2)
p12 <- c(2,2,3)
24*8*4
768/.4
24*8
192/.4
192*.4
192/.4
480/60
.15*80
.2*40
37/180 * 2675
37/360 * 2675
.5*6*4
.5*6*3
77+22
99+22
121+12
133+77
7/.85
.85*8
.85*9
1998-22
2015-1976
1997-22
2015-1975
2002-22
2015-1980
1+3+5
a <- (1,3,5,7,9,11,13,15,17,19)
a <- c(1,3,5,7,9,11,13,15,17,19)
sum(a)
a <- c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33)
sum(a)
a <- c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51)
sum(a)
a <- c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53)
sum(a)
length(a)
27*27
81+12+26+26+81
pi * 3 * 3 * 10
22/7
pi
22/7 - pi
tan(40)
?tan
?tan2
?tanpi
.65 * 399
83+83+12+28+28
87+12+32+31+87
91+34+34+12+91
3+13+75
5.84*4+9.99*4+17.99*2+6.49*6+3.49*4+6.74/.9+1.79/.9+3.40/.57
7+1+1+1+2+1+3+1+1+1+1+1+23+1+2
4+1+1+4+1+1+23+1+7
5+2+2+5+2+2+23+2
4+5+1+3+3+22+3
41+8
56-49
3+1+2+2+1+1+1+22+2+1
36+9
4+2+3+3+2+2+2+22+1+3+1
56-45
6+2+2+3+2+2+2+23+2+1
5+1+1+2+1+1+1+21+1+1+9
2+2+2+4+2+2+2+5+16+3+2
56-42
2+2+3+5+2+2+4+15+2+2
8+3+2+8+25
365+365+31+28+31+30+31+30+31+31+28
24*5
144/4
6.78360-6.47577
.30783/1.018
4+1+1+4+1+1+6
31-18
4+5+1+3+1+1+1+7
2+1+2+2
4+2+1+7+10+7
1+1+3+3+3
8+3+2
2+12+3+3
23-2
12+3+1
5+1+3+1
3+3+3
4+6+2+8
1+4+2+1+3
2+6+8+2
2+1
7+1+9+3+3
32-23
8+1+5
14+2+1+2
19+4+2+3+4+7
14+35
16+7+4+5+6
49-38
11+36
16+11+7+5
47-39
4+1+2+7+2+4
18+3+2+1+2+1+5
14+3+2+1+2+1+5
5+11+2+1+2+4+8
.351*6.69381
2.349527+3.983
.379*6.69381
2.536954+4.284
sqrt(2)
414214*2 + 1
.414214*2 + 1
4/130
9/137
6/137
4/137
177+12+46+12+46+180
180*2+12+46+12+46+12
8+7+7+2+18+6+3+2+1+14
82-68
?read.csv
getwd()
setwd("~/Desktop/reddit_classification")
file = "d2v_w2v_results.csv"
data = read.csv(file)
View(data)
require(ggplot2)
qplot(dimensionality, accuracy, data = data)
qplot(Dimensionality, Accuracy, data = data)
qplot(Dimensionality, Accuracy, data = data, geom = 'smooth')
qplot(Dimensionality, Accuracy, data = data, geom = 'smooth', main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Dimensionality, Accuracy, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Dimensionality, Precision, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Dimensionality, Recall, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Dimensionality, "F1 Score", data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Dimensionality, F1 Score, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
names(data)
qplot(Dimensionality, F1.Score, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Dimensionality, c(Accuracy, Recall), data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Dimensionality, Accuracy, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Context.Size, Accuracy, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Context.Size, Recall, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
qplot(Context.Size, Precision, data = data, geom = c('smooth', 'point'), main = "Doc2Vec Performance as a Function of Dimensionality")
test_data_long <- melt(data, id="Dimensionality")
library("reshape2")
test_data_long <- melt(data, id="Dimensionality")
View(test_data_long)
stacked <- with(data=data,
data.frame(value = c(Accuracy, Recall),
measure = factor(rep(c("Accuracy","Recall"),
each = NROW(data))),
Dimensions = rep(Dimensionality, 2)))
View(stacked)
ggplot(stacked, aes(Dimensions, value, colour = measure))
p = ggplot(stacked, aes(Dimensions, value, colour = measure))
p + geom_smooth()
p + geom_smooth() + geom_point()
stacked <- with(data=data,
data.frame(Score = c(Accuracy, Recall),
Metric = factor(rep(c("Accuracy","Recall"),
each = NROW(data))),
Dimensions = rep(Dimensionality, 2)))
p = ggplot(stacked, aes(Dimensions, Score, colour = Metric))
p + geom_smooth() + geom_point()
stacked <- with(data=data,
data.frame(Score = c(Accuracy, Recall),
Metric = factor(rep(c("Accuracy","Recall"),
each = NROW(data))),
Dimensions = rep(Dimensionality, 2))
Context.Window = Context.Size)
stacked <- with(data=data,
data.frame(Score = c(Accuracy, Recall),
Metric = factor(rep(c("Accuracy","Recall"),
each = NROW(data))),
Dimensions = rep(Dimensionality, 2)
Context.Window = Context.Size))
stacked <- with(data=data,
data.frame(Score = c(Accuracy, Recall),
Metric = factor(rep(c("Accuracy","Recall"),
each = NROW(data))),
Dimensions = rep(Dimensionality, 2),
Context.Window = Context.Size))
p = ggplot(stacked, aes(Dimensions, Score, colour = Metric))
p + geom_smooth() + geom_point()
q = ggplot(stacked, aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point()
p = ggplot(stacked, aes(Dimensions, Score, colour = Metric))
p + geom_smooth() + geom_point()
q = ggplot(stacked, aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point()
p = ggplot(stacked, aes(Dimensions, Score, colour = Metric),
main = "Dimensionality versus Performance")
p + geom_smooth() + geom_point()
?ggplot
p = ggplot(stacked, aes(Dimensions, Score, colour = Metric))
p + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
q = ggplot(stacked, aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
depth <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 25, 35, 50)
scores <- c(.48826, .53631, .5639, .58172, .59443,
.60686, .61582, .6209, .62823, .63216,
.63524, 0.63606, .6412, .64337, .64141,
.64087, .63767, .61309, .55237)
qplot(depth, scores, ylim = c(.4, 0.8), xlab = 'Tree Depth', ylab =
'Model Accuracy', geom = 'smooth', main = 'Adaboost Performance At Varying Depths')
p = ggplot(subset(stacked, Context.Window == 8), aes(Dimensions, Score, colour = Metric))
p + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
p = ggplot(subset(stacked, Context.Window %in% c(8)), aes(Dimensions, Score, colour = Metric))
p + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
p = ggplot(subset(stacked, Context.Window %in% c(6,8)), aes(Dimensions, Score, colour = Metric))
p + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
q = ggplot(subset(stacked, Dimensions %in% c(300,400)), aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
q = ggplot(subset(stacked, Dimensions %in% c(100,150, 200, 300,400)), aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
q = ggplot(subset(stacked, Dimensions %in% c(300,400, 500, 600)), aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
q = ggplot(subset(stacked, Dimensions %in% c(250, 300,400, 500, 600)), aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
q = ggplot(subset(stacked, Dimensions %in% c(200, 250, 300,400, 500, 600)), aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
q = ggplot(subset(stacked, Dimensions %in% c(250, 300,400, 500, 600)), aes(Context.Window, Score, colour = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
read_logs <- function (filename, ngram) {
logs <- read.table(filename, header = FALSE, sep = "", col.names =
c("level", "zoom", "lamb", "lambda", "sc", "score"),
skip=9, fill = TRUE)
keep <- c("lambda", "score")
logs <- na.omit(logs)
logs <- logs[keep]
logs["ngram"] <- ngram
logs
}
files <- c("logs_1", "logs_2", "logs_3", "logs_4")
data <- lapply(files, function(x) read_logs(x, which(files == x)))
svm <- rbind(data[[1]],data[[2]],data[[3]],data[[4]])
svm$ngram = factor(svm$ngram)
dim(svm)
qplot(log10(lambda), score, data = svm, color = ngram, xlab =
"Log Lambda Regularization Parameter", ylab = "Model Accuracy",
main = "SVM bag-of-ngrams", ylim = c(0, 1), geom = 'smooth')
p = ggplot(subset(stacked, Context.Window %in% c(5, 6, 8, 10, 12, 15)),
aes(Dimensions, Score, color = Metric))
p + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
q = ggplot(subset(stacked, Dimensions %in% c(100, 150, 200, 250, 300,400, 500, 600)),
aes(Context.Window, Score, color = Metric))
q + geom_smooth() + geom_point() +ggtitle("Context Window Size versus Performance")
scores
max(sscores)
max(scores)
.83-.51
.83-.63
.63-.55
.85-.48
.85-.61
file2 = "w2v_results_copy.csv"
data = read.csv(file2)
w = ggplot(data, aes(Dimensions, Accuracy, color = Weighted)))
w = ggplot(data, aes(Dimensions, Accuracy, color = Weighted))
w + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
w = ggplot(data, aes(Dimensionality, Accuracy, color = Weighted))
w + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
data = read.csv(file2)
w = ggplot(data, aes(Dimensionality, Accuracy, color = Weighted))
w + geom_smooth() + geom_point() + ggtitle("Dimensionality versus Performance")
x = ggplot(data, aes(Context.Size, Accuracy, color = Weighted))
x + geom_smooth() + geom_point() + ggtitle("Context Size versus Performance")
