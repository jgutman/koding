from deepdist import DeepDist
from gensim.models.word2vec import Word2Vec
from pyspark import SparkContext
import os

sc = SparkContext()
directory = os.path.abspath(os.path.dirname('/Users/jacqueline/Desktop/Statistical_NLP/nlp_data/data5/training-data/1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/news.en-00001-of-00100'))
corpus = sc.textFile(directory).map(lambda s: s.split())

def gradient(model, sentences):  # executes on workers
    syn0, syn1 = model.syn0.copy(), model.syn1.copy()
    model.train(sentences)
    return {'syn0': model.syn0 - syn01, 'syn1': model.syn1 - syn1}

def descent(model, update):      # executes on master
    model.syn0 += update['syn0']
    model.syn1 += update['syn1']

with DeepDist(Word2Vec(corpus.collect())) as dd:

    dd.train(corpus, gradient, descent)
    print dd.model.most_similar(positive=['woman', 'king'], negative=['man'])
